import os
import json
import re
import requests
import base64
from dotenv import load_dotenv
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from telegram import Update, error
import asyncio
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords
import nltk

# === NLTK setup ===
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
if not BOT_TOKEN:
    raise RuntimeError("BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env")

OLLAMA_API_URL = os.getenv("OLLAMA_API_URL", "http://localhost:11434/api/chat")  # ‚Üê –í–ê–ñ–ù–û: /api/chat, –Ω–µ /generate
MODEL_NAME = os.getenv("MODEL_NAME", "gemma3:4b")

FAQ_PATH = "faq.json"
knowledge_base = []
faq_texts = []

if os.path.exists(FAQ_PATH):
    try:
        with open(FAQ_PATH, "r", encoding="utf-8") as f:
            raw_data = json.load(f)
            knowledge_base = [
                {
                    "context": item.get("context", ""),
                    "keywords": [kw.lower().strip() for kw in item.get("keywords", [])]
                }
                for item in raw_data
                if item.get("context")
            ]
        faq_texts = [
            " ".join(entry["keywords"]) + " " + entry["context"]
            for entry in knowledge_base
        ]
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(knowledge_base)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è RAG")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")

stemmer = PorterStemmer()
try:
    russian_stopwords = set(stopwords.words('russian'))
except:
    russian_stopwords = set()

def preprocess_text(text: str) -> str:
    text = re.sub(r"[^–∞-—è—ëa-z\s]", " ", text.lower())
    words = text.split()
    if russian_stopwords:
        words = [w for w in words if w not in russian_stopwords]
    words = [stemmer.stem(w) for w in words]
    return " ".join(words)

tfidf = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 6), lowercase=False, max_features=1000)
tfidf_matrix = None
if faq_texts:
    processed_faq = [preprocess_text(txt) for txt in faq_texts]
    tfidf_matrix = tfidf.fit_transform(processed_faq)

def retrieve_context(user_question: str, similarity_threshold: float = 0.1) -> str:
    if not knowledge_base:
        return ""
    norm_question = preprocess_text(user_question)
    for entry in knowledge_base:
        for kw in entry["keywords"]:
            if preprocess_text(kw) in norm_question:
                return entry["context"]
    if tfidf_matrix is not None:
        query_vec = tfidf.transform([norm_question])
        similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()
        best_idx = similarities.argmax()
        if similarities[best_idx] >= similarity_threshold:
            return knowledge_base[best_idx]["context"]
    return ""

# === –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø: –∑–∞–ø—Ä–æ—Å –∫ Ollama —á–µ—Ä–µ–∑ /api/chat —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ===
def ask_model_ollama(messages: list) -> str:
    try:
        response = requests.post(
            OLLAMA_API_URL,
            json={
                "model": MODEL_NAME,
                "messages": messages,
                "stream": False,
                "options": {"temperature": 0.9}
            },
            timeout=120
        )
        response.raise_for_status()
        return response.json().get("message", {}).get("content", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç.")
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏: {str(e)}"

# === –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64 ===
def image_to_base64(image_path: str) -> str:
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

TEACHER_ROLE = (
    "–¢—ã –ª–∏—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä–∞ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –ê–ª–µ–∫—Å–µ—è. (@AVick23) "
    "–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –µ–≥–æ –∫—É—Ä—Å–∞—Ö, —É—Ä–æ–∫–∞—Ö, –æ–±—É—á–µ–Ω–∏–∏, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏, IT, "
    "–∞ —Ç–∞–∫–∂–µ –Ω–∞ '–ö—Ç–æ —Ç–∞–∫–æ–π –ê–ª–µ–∫—Å–µ–π?' –∏ '–ö—Ç–æ —Ç—ã?'. "
    "–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º ‚Äî 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞. "
    "–ì–æ–≤–æ—Ä–∏ —Å–ø–æ–∫–æ–π–Ω–æ, –≤–µ–∂–ª–∏–≤–æ –∏ –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏, –Ω–æ –±–µ–∑ —ç–º–æ–¥–∑–∏, —Å–ª–µ–Ω–≥–∞ –∏ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤. "
    "–ï—Å–ª–∏ —Ç–µ–º–∞ –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —É–∫–∞–∑–∞–Ω–Ω—ã–º ‚Äî –≤–µ–∂–ª–∏–≤–æ –æ—Ç–∫–∞–∂–∏—Å—å –æ—Ç–≤–µ—á–∞—Ç—å."
)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_msg = (
        "üë®‚Äçüè´ –ü—Ä–∏–≤–µ—Ç! –Ø ‚Äî –≤–∞—à –≥–∏–¥ –ø–æ –æ–±—É—á–µ–Ω–∏—é.\n"
        "–ú–æ–≥—É –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∫—É—Ä—Å–∞–º, –∞ —Ç–∞–∫–∂–µ –ø–æ–Ω–∏–º–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n\n"
        "–í–≤–µ–¥–∏—Ç–µ '–æ—á–∏—Å—Ç–∏—Ç—å', —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥."
    )
    await update.message.reply_text(welcome_msg)

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ ===
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text.strip()
    if user_message.lower() in ("–æ—á–∏—Å—Ç–∏—Ç—å", "clear", "—Å–±—Ä–æ—Å–∏—Ç—å"):
        context.user_data['chat_history'] = []
        await update.message.reply_text("‚úÖ –î–∏–∞–ª–æ–≥ –æ—á–∏—â–µ–Ω.")
        return

    context.user_data.setdefault('chat_history', [])
    context.user_data['chat_history'].append({"role": "user", "content": user_message})

    retrieved_context = retrieve_context(user_message)
    if retrieved_context:
        system_msg = {"role": "system", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {retrieved_context}"}
        messages = [system_msg] + context.user_data['chat_history'][-6:]
    else:
        messages = [{"role": "system", "content": TEACHER_ROLE}] + context.user_data['chat_history'][-6:]

    thinking = await update.message.reply_text("ü§î –î—É–º–∞—é...")
    loop = asyncio.get_running_loop()
    response = await loop.run_in_executor(None, lambda: ask_model_ollama(messages))
    await thinking.delete()
    
    context.user_data['chat_history'].append({"role": "assistant", "content": response})
    await update.message.reply_text(response)

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ===
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    photo = update.message.photo[-1]
    file = await context.bot.get_file(photo.file_id)
    file_path = f"temp_{photo.file_id}.jpg"
    await file.download_to_drive(file_path)

    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
        img_b64 = image_to_base64(file_path)

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
        user_msg = {"role": "user", "content": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.", "images": [img_b64]}
        context.user_data.setdefault('chat_history', []).append(user_msg)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
        messages = [{"role": "system", "content": TEACHER_ROLE}] + context.user_data['chat_history'][-6:]

        thinking = await update.message.reply_text("üñºÔ∏è –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
        loop = asyncio.get_running_loop()
        response = await loop.run_in_executor(None, lambda: ask_model_ollama(messages))
        await thinking.delete()

        context.user_data['chat_history'].append({"role": "assistant", "content": response})
        await update.message.reply_text(response)

    finally:
        if os.path.exists(file_path):
            os.remove(file_path)

def main():
    application = Application.builder().token(BOT_TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))  # ‚Üê –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Ollama.")
    application.run_polling()

if __name__ == "__main__":
    main()